Day 1: Practice with a single node k8 cluster using minikube
------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------
-Install docker
-Install Docker version manager

-Install kubectl:
  curl -Lo kubectl http://storage.googleapis.com/kubernetes-release/release/v1.5.1/bin/darwin/amd64/kubectl && chmod +x kubectl && sudo mv kubectl /usr/local/bin/

- Install minikube
  curl -Lo minikube https://storage.googleapis.com/minikube/releases/v0.14.0/minikube-darwin-amd64 && chmod +x minikube && sudo mv minikube /usr/local/bin/

-Start minikube local kubernetes cluster
  minikube start
    (This starts a local VM using virtualbox. Check Virtualbox UI for checking the VM)

- Check cluster status
  minikube status

- SSH into the minikube node
  minikube ssh

- Point docker client to point to minikube instance
  eval $(minikube docker-env)
    This sets the docker server. So running "docker version" gives you the info about both docker client and server:
                  macbook-pro:~ rajatlocal$ docker version
                  Client:
                  Version:      1.12.5
                  API version:  1.23
                  Go version:   go1.6.4
                  Git commit:   7392c3b
                  Built:        Fri Dec 16 06:14:34 2016
                  OS/Arch:      darwin/amd64

                  Server:
                  Version:      1.11.1
                  API version:  1.23
                  Go version:   go1.5.4
                  Git commit:   5604cbe
                  Built:        Wed Apr 27 00:34:20 2016
                  OS/Arch:      linux/amd64

- Shows the nodes running the cluster
    kubectl get nodes

- Shows the status of the cluster
    kubectl get cs

- To point to different environments
    kubectl config use-context <minikube>

- Create a new deployment using a nhinx image at port 80
    kubectl  run nginx-web --image=nginx --port=80

- See the deployments
    kubectl get deployment

- See the pods
    kubectl get pods

- Expose the deployment to outside world. This exposes the deployment as a service (NodePort)
    kubectl expose deployment nginx-web --target-port=80 --type=NodePort

- Show the services exposed
    kubectl get svc

- Shows the minikube dashboard with the deployments, services and pods
    minikube dashboard

- Show the minikube IP
    minikube ip
------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------
Day 2: Use a multi node K8 cluster from core-os
------------------------------------------------------------------------------------------------------------------------------
------------------------------------------------------------------------------------------------------------------------------
- Setup application and docker
    Follow https://github.com/rajatparida86/kubernetes
    Location: /vlab/dev/github/k8-pythonapp/

- Deploy multi node kubernets cluster using vagrant (Ref: https://coreos.com/kubernetes/docs/latest/kubernetes-on-vagrant.html)

    - Location: /vlab/dev/github/coreos-kubernetes

    - Catch: openssl error while running vagrant command from the above location
        Resolution:
          run -- sudo ln -sf /usr/local/bin/openssl /opt/vagrant/embedded/bin/openssl

    - Once vagrant starts up the cluster, use a custom KUBECONFIG path to point kubectl to the appropriate cluster:
        export KUBECONFIG="${KUBECONFIG}:$(pwd)/kubeconfig"
        kubectl config use-context vagrant-multi

    - Check the nodes running
        kubectl get nodes

    - Describe the cluster:
        kubectl cluster-info

    - Check the status of all components
        kubectl get cs

- Write the 'yml' files for the "POD" and "Service" and "Replication cluster" definitions
    Location -- /vlab/dev/github/k8-pythonapp/Kubernetes

- Deploy the pods and services to the kuberetes cluster
    kubectl create -f <pod yml file>

- Check if the pods and services are running
    kubectl get pods
    kubectl get svc

- SSH into the pods
    kubectl exec -it <pod name> /bin/bash

- Check the IP and Port for the service to access the application
    kubectl get nodes
        NAME           STATUS                     AGE
        172.17.4.101   Ready,SchedulingDisabled   3h
        172.17.4.201   Ready                      3h

    kubectl describe svc <service name>
        Name:			web
        Namespace:		default
        Labels:			app=demo
            name=web
        Selector:		name=web
        Type:			NodePort
        IP:			10.3.0.176
        Port:			<unset>	80/TCP
        NodePort:		<unset>	30239/TCP
        Endpoints:		10.2.71.10:5000
        Session Affinity:	None
        No events.

    Access the application:
      curl <node IP>:<service nodeport>

  - Create a replication controller (Maintains the count of pods-- helps in scaling up/down)
      kubectl create -f <replication controller yml>

  - See the list of RCs
      kubectl get rc

  - Scale up the number of pods using a RC
      kubectl scale rc web --replicas=5
